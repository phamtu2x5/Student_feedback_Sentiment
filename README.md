# Student Feedback Sentiment Analysis API

Há»‡ thá»‘ng phÃ¢n tÃ­ch sentiment vÃ  topic cho feedback cá»§a sinh viÃªn sá»­ dá»¥ng PhoBERT Multi-Task Learning, Ä‘Æ°á»£c deploy trÃªn Render.

## ğŸš€ TÃ­nh nÄƒng

- **Sentiment Analysis**: PhÃ¢n loáº¡i sentiment thÃ nh 3 loáº¡i (positive, neutral, negative)
- **Topic Classification**: PhÃ¢n loáº¡i chá»§ Ä‘á» thÃ nh 4 loáº¡i (lecturer, training_program, facility, others)
- **Multi-task Learning**: Xá»­ lÃ½ cáº£ 2 nhiá»‡m vá»¥ cÃ¹ng lÃºc vá»›i má»™t model duy nháº¥t
- **RESTful API**: Giao diá»‡n API Ä‘Æ¡n giáº£n vÃ  dá»… sá»­ dá»¥ng
- **Vietnamese Support**: Tá»‘i Æ°u cho tiáº¿ng Viá»‡t vá»›i PhoBERT
- **Production Ready**: ÄÆ°á»£c tá»‘i Æ°u cho deployment trÃªn cloud

## ğŸ› ï¸ CÃ i Ä‘áº·t Local

1. **Clone repository:**

```bash
git clone <repository-url>
cd Student_feedback_Sentiment
```

2. **CÃ i Ä‘áº·t dependencies:**

```bash
pip install -r requirements.txt
```

3. **Cháº¡y á»©ng dá»¥ng:**

```bash
python app.py
```

API sáº½ cháº¡y táº¡i: `http://localhost:10000`

## ğŸš€ Deployment trÃªn Render

### BÆ°á»›c 1: Chuáº©n bá»‹ Repository

1. Push code lÃªn GitHub repository
2. Äáº£m báº£o cÃ³ cÃ¡c file cáº§n thiáº¿t:
   - `app.py` - Flask application
   - `PhoBERTMultiTask.py` - Model architecture
   - `requirements.txt` - Dependencies
   - `render.yaml` - Render configuration
   - `phobert_multitask_model/` - Model files

### BÆ°á»›c 2: Deploy trÃªn Render

1. ÄÄƒng nháº­p vÃ o [Render](https://render.com)
2. Click **"New +"** â†’ **"Web Service"**
3. Connect GitHub repository
4. Render sáº½ tá»± Ä‘á»™ng detect `render.yaml` vÃ  cáº¥u hÃ¬nh:
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `gunicorn --bind 0.0.0.0:$PORT app:app`
   - **Python Version**: 3.9.16

### BÆ°á»›c 3: Kiá»ƒm tra Deployment

- Render sáº½ tá»± Ä‘á»™ng build vÃ  deploy
- Thá»i gian build: ~5-10 phÃºt (do download model)
- URL sáº½ cÃ³ dáº¡ng: `https://phobert-multitask-api.onrender.com`

## ğŸ“– API Usage

### Base URL (Production)

```
https://phobert-multitask-api.onrender.com
```

### Endpoints

#### Health Check

```http
GET /
```

#### Predict Sentiment & Topic

```http
POST /predict
Content-Type: application/json
```

**Request:**

```json
{
  "text": "Giáº£ng viÃªn giáº£ng bÃ i ráº¥t hay vÃ  dá»… hiá»ƒu"
}
```

**Response:**

```json
{
  "sentiment": "positive",
  "topic": "lecturer"
}
```

### Test API

**Sá»­ dá»¥ng curl:**

```bash
# Test health check
curl https://phobert-multitask-api.onrender.com/

# Test prediction
curl -X POST https://phobert-multitask-api.onrender.com/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Tháº§y cÃ´ giáº£ng bÃ i ráº¥t hay vÃ  dá»… hiá»ƒu"}'
```

**Sá»­ dá»¥ng Python:**

```python
import requests

# Test prediction
response = requests.post(
    'https://phobert-multitask-api.onrender.com/predict',
    json={'text': 'PhÃ²ng há»c ráº¥t rá»™ng rÃ£i vÃ  thoÃ¡ng mÃ¡t'}
)
print(response.json())
```

## ğŸ“ Cáº¥u trÃºc Project

```
Student_feedback_Sentiment/
â”œâ”€â”€ app.py                    # Flask API server
â”œâ”€â”€ PhoBERTMultiTask.py       # Model architecture
â”œâ”€â”€ phobert_multitask_model/  # Pre-trained model files
â”‚   â”œâ”€â”€ multitask_model.bin   # Model weights
â”‚   â”œâ”€â”€ config.json          # Model configuration
â”‚   â””â”€â”€ tokenizer files...   # PhoBERT tokenizer
â”œâ”€â”€ requirements.txt         # Production dependencies
â”œâ”€â”€ render.yaml             # Render deployment config
â””â”€â”€ README.md               # Documentation
```

## ğŸ—ï¸ Model Architecture

- **Base Model**: PhoBERT-base (vinai/phobert-base)
- **Architecture**: Multi-task learning vá»›i 2 classification heads
- **Input**: Vietnamese text (max 128 tokens)
- **Output**:
  - Sentiment: 3 classes (negative, neutral, positive)
  - Topic: 4 classes (lecturer, training_program, facility, others)

## ğŸ“Š Performance

- **Model Size**: ~440MB (PhoBERT-base + custom heads)
- **Cold Start**: ~30-60s (first request after idle)
- **Warm Requests**: ~100-200ms per request
- **Memory Usage**: ~1-2GB RAM
- **Accuracy**:
  - Sentiment: ~85-90% (validation set)
  - Topic: ~80-85% (validation set)

## ğŸ”§ Production Optimizations

- **Gunicorn WSGI Server**: Thay tháº¿ Flask dev server
- **Minimal Dependencies**: Chá»‰ giá»¯ láº¡i packages cáº§n thiáº¿t
- **Environment Variables**: Tá»± Ä‘á»™ng detect PORT tá»« Render
- **Error Handling**: Comprehensive error responses
- **Health Check**: Endpoint Ä‘á»ƒ monitor service

## ğŸš¨ Troubleshooting

### Render Deployment Issues

1. **Build Timeout**: Model download máº¥t quÃ¡ nhiá»u thá»i gian

   - Solution: Upgrade lÃªn paid plan hoáº·c optimize model size

2. **Memory Issues**: Out of memory khi load model

   - Solution: Upgrade lÃªn plan cÃ³ nhiá»u RAM hÆ¡n

3. **Cold Start**: Request Ä‘áº§u tiÃªn cháº­m
   - Solution: Sá»­ dá»¥ng Render Cron Jobs Ä‘á»ƒ keep-alive

### Common Errors

- **502 Bad Gateway**: Service chÆ°a sáºµn sÃ ng, Ä‘á»£i thÃªm vÃ i phÃºt
- **Timeout**: Model loading máº¥t thá»i gian, retry request
- **Memory Error**: Upgrade Render plan

## ğŸ’¡ Tips for Production

1. **Monitor Usage**: Theo dÃµi Render dashboard
2. **Set Alerts**: Cáº¥u hÃ¬nh alerts cho downtime
3. **Backup Model**: LÆ°u trá»¯ model files á»Ÿ nÆ¡i an toÃ n
4. **Version Control**: Tag releases khi deploy
5. **Logging**: Monitor application logs

## ğŸ“ Support

- **Render Dashboard**: Monitor service status
- **Render Logs**: Check application logs
- **GitHub Issues**: Report bugs vÃ  feature requests

---

â­ **Project Ä‘Æ°á»£c tá»‘i Æ°u cho production deployment trÃªn Render!** â­
